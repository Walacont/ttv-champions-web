{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# RF-DETR Training fur Tischtennis Ball & Schlager Erkennung\n",
    "\n",
    "Dieses Notebook trainiert ein **RF-DETR** Modell (Apache 2.0 Lizenz, kommerziell nutzbar!) \n",
    "fur die Erkennung von:\n",
    "- **Ball** (TT-Ball, weiss/orange, 3-10 Pixel)\n",
    "- **Racket** (TT-Schlager)\n",
    "- **Table** (Tischtennis-Tisch, optional)\n",
    "\n",
    "## Voraussetzungen\n",
    "1. Google Colab Account (kostenlos, T4 GPU)\n",
    "2. Roboflow Account mit gelabeltem Dataset\n",
    "3. Roboflow API Key\n",
    "\n",
    "## Lizenzen (alle kommerziell nutzbar!)\n",
    "- RF-DETR: Apache 2.0\n",
    "- ONNX Runtime: MIT\n",
    "- Supervision: MIT\n",
    "- Roboflow: Dein Model gehoert dir"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Schritt 1: GPU pruefen & Pakete installieren"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# GPU pruefen - sollte T4 oder besser sein\n",
    "!nvidia-smi\n",
    "\n",
    "import torch\n",
    "print(f\"PyTorch: {torch.__version__}\")\n",
    "print(f\"CUDA verfuegbar: {torch.cuda.is_available()}\")\n",
    "if torch.cuda.is_available():\n",
    "    print(f\"GPU: {torch.cuda.get_device_name(0)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# RF-DETR und Abhaengigkeiten installieren\n",
    "!pip install -q rfdetr roboflow supervision onnx onnxruntime"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Schritt 2: Dataset von Roboflow laden\n",
    "\n",
    "### Vorbereitung in Roboflow:\n",
    "1. Erstelle ein Projekt: \"Table Tennis Detection\" (Object Detection)\n",
    "2. Klassen: `ball`, `racket`, `table`\n",
    "3. Lade deine Videos hoch (Roboflow extrahiert Frames)\n",
    "4. Zeichne Bounding Boxes um Ball, Schlager, Tisch\n",
    "5. Mindestens 300+ Bilder labeln\n",
    "6. Dataset Version generieren (mit Augmentation: Flip, Brightness, Blur)\n",
    "7. API Key kopieren"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================\n",
    "# HIER DEINE WERTE EINTRAGEN:\n",
    "# ============================================\n",
    "\n",
    "ROBOFLOW_API_KEY = \"DEIN_API_KEY_HIER\"  # Aus Roboflow Settings\n",
    "ROBOFLOW_WORKSPACE = \"dein-workspace\"    # Dein Workspace-Name\n",
    "ROBOFLOW_PROJECT = \"table-tennis-detection\"  # Dein Projekt-Name\n",
    "ROBOFLOW_VERSION = 1  # Dataset-Version\n",
    "\n",
    "# ============================================"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from roboflow import Roboflow\n",
    "\n",
    "rf = Roboflow(api_key=ROBOFLOW_API_KEY)\n",
    "project = rf.workspace(ROBOFLOW_WORKSPACE).project(ROBOFLOW_PROJECT)\n",
    "version = project.version(ROBOFLOW_VERSION)\n",
    "\n",
    "# Dataset im COCO-Format herunterladen (RF-DETR braucht COCO)\n",
    "dataset = version.download(\"coco\")\n",
    "\n",
    "print(f\"\\nDataset heruntergeladen nach: {dataset.location}\")\n",
    "print(f\"Train-Bilder: {dataset.location}/train\")\n",
    "print(f\"Valid-Bilder: {dataset.location}/valid\")\n",
    "print(f\"Test-Bilder:  {dataset.location}/test\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dataset-Statistiken anzeigen\n",
    "import json\n",
    "import os\n",
    "\n",
    "for split in ['train', 'valid', 'test']:\n",
    "    ann_path = os.path.join(dataset.location, split, '_annotations.coco.json')\n",
    "    if os.path.exists(ann_path):\n",
    "        with open(ann_path) as f:\n",
    "            data = json.load(f)\n",
    "        cats = {c['id']: c['name'] for c in data['categories']}\n",
    "        ann_counts = {}\n",
    "        for ann in data['annotations']:\n",
    "            name = cats[ann['category_id']]\n",
    "            ann_counts[name] = ann_counts.get(name, 0) + 1\n",
    "        print(f\"\\n{split.upper()}:\")\n",
    "        print(f\"  Bilder: {len(data['images'])}\")\n",
    "        print(f\"  Annotationen: {len(data['annotations'])}\")\n",
    "        for name, count in sorted(ann_counts.items()):\n",
    "            print(f\"    {name}: {count}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Schritt 3: RF-DETR trainieren\n",
    "\n",
    "RF-DETR verwendet einen **DINOv2-Backbone** der besonders gut bei kleinen Objekten ist - perfekt fuer TT-Baelle!\n",
    "\n",
    "### Training-Parameter:\n",
    "- `epochs`: 50-100 (mehr = besser, aber laenger)\n",
    "- `batch_size`: 8-16 (je nach GPU-Speicher)\n",
    "- `imgsz`: 640 (Standard) oder 960 (besser fuer kleine Objekte, aber langsamer)\n",
    "- `lr`: 1e-4 (Standard, gut fuer Fine-Tuning)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from rfdetr import RFDETRBase\n",
    "\n",
    "# RF-DETR Base Modell (guter Kompromiss aus Genauigkeit und Geschwindigkeit)\n",
    "# Alternativen: RFDETRSmall (schneller), RFDETRLarge (genauer)\n",
    "model = RFDETRBase()\n",
    "\n",
    "# Training starten\n",
    "model.train(\n",
    "    dataset_dir=dataset.location,\n",
    "    epochs=75,           # 75 Epochen - guter Kompromiss\n",
    "    batch_size=8,        # 8 fuer T4 GPU (16GB VRAM)\n",
    "    imgsz=640,           # 640px - Standard, fuer mehr Genauigkeit 960 nutzen\n",
    "    lr=1e-4,             # Learning Rate\n",
    "    grad_accum_steps=4,  # Gradient Accumulation (simuliert groessere Batch)\n",
    "    use_ema=True,        # Exponential Moving Average (stabilisiert Training)\n",
    "    device=\"cuda\"\n",
    ")\n",
    "\n",
    "print(\"\\nTraining abgeschlossen!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Schritt 4: Modell testen & evaluieren"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import supervision as sv\n",
    "from PIL import Image\n",
    "import glob\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Test-Bilder laden\n",
    "test_images = glob.glob(os.path.join(dataset.location, 'test', '*.jpg'))\n",
    "test_images += glob.glob(os.path.join(dataset.location, 'test', '*.png'))\n",
    "\n",
    "if not test_images:\n",
    "    test_images = glob.glob(os.path.join(dataset.location, 'valid', '*.jpg'))\n",
    "    test_images += glob.glob(os.path.join(dataset.location, 'valid', '*.png'))\n",
    "\n",
    "print(f\"{len(test_images)} Test-Bilder gefunden\")\n",
    "\n",
    "# 6 zufaellige Bilder testen\n",
    "import random\n",
    "sample_images = random.sample(test_images, min(6, len(test_images)))\n",
    "\n",
    "fig, axes = plt.subplots(2, 3, figsize=(18, 12))\n",
    "axes = axes.flatten()\n",
    "\n",
    "# Annotator fuer Visualisierung\n",
    "box_annotator = sv.BoxAnnotator(thickness=2)\n",
    "label_annotator = sv.LabelAnnotator(text_scale=0.5, text_thickness=1)\n",
    "\n",
    "for i, img_path in enumerate(sample_images):\n",
    "    image = Image.open(img_path)\n",
    "    detections = model.predict(image, threshold=0.3)\n",
    "    \n",
    "    # Supervision Detections\n",
    "    import numpy as np\n",
    "    annotated = np.array(image)\n",
    "    annotated = box_annotator.annotate(annotated, detections)\n",
    "    \n",
    "    labels = []\n",
    "    for j in range(len(detections)):\n",
    "        conf = detections.confidence[j]\n",
    "        cls_id = detections.class_id[j]\n",
    "        cls_name = detections.data.get('class_name', ['?'])[j] if 'class_name' in detections.data else str(cls_id)\n",
    "        labels.append(f\"{cls_name} {conf:.2f}\")\n",
    "    \n",
    "    annotated = label_annotator.annotate(annotated, detections, labels=labels)\n",
    "    \n",
    "    axes[i].imshow(annotated)\n",
    "    axes[i].set_title(os.path.basename(img_path))\n",
    "    axes[i].axis('off')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig('test_predictions.png', dpi=150)\n",
    "plt.show()\n",
    "print(\"Ergebnisse gespeichert als test_predictions.png\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Schritt 5: ONNX Export (fuer Browser-Inferenz)\n",
    "\n",
    "Der ONNX-Export erzeugt ein Modell das mit **onnxruntime-web** direkt im Browser laufen kann.\n",
    "Das bedeutet: keine Server-Kosten, alles laeuft lokal beim User!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Bestes Modell als ONNX exportieren\n",
    "model.export(\"tt-detector.onnx\")\n",
    "\n",
    "# Dateigröße prüfen\n",
    "onnx_size = os.path.getsize('tt-detector.onnx') / (1024 * 1024)\n",
    "print(f\"\\nONNX Modell exportiert: tt-detector.onnx\")\n",
    "print(f\"Dateigröße: {onnx_size:.1f} MB\")\n",
    "print(f\"\\nNaechster Schritt: Lade tt-detector.onnx herunter und lege es in:\")\n",
    "print(f\"  ttv-champions-web/public/models/tt-detector.onnx\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ONNX Modell validieren\n",
    "import onnx\n",
    "import onnxruntime as ort\n",
    "\n",
    "# Modell laden und pruefen\n",
    "onnx_model = onnx.load('tt-detector.onnx')\n",
    "onnx.checker.check_model(onnx_model)\n",
    "print(\"ONNX Modell ist valide!\")\n",
    "\n",
    "# Input/Output Format anzeigen\n",
    "session = ort.InferenceSession('tt-detector.onnx')\n",
    "\n",
    "print(\"\\nInputs:\")\n",
    "for inp in session.get_inputs():\n",
    "    print(f\"  {inp.name}: {inp.shape} ({inp.type})\")\n",
    "\n",
    "print(\"\\nOutputs:\")\n",
    "for out in session.get_outputs():\n",
    "    print(f\"  {out.name}: {out.shape} ({out.type})\")\n",
    "\n",
    "# Quick Inference Test\n",
    "import numpy as np\n",
    "dummy_input = np.random.randn(1, 3, 640, 640).astype(np.float32)\n",
    "results = session.run(None, {session.get_inputs()[0].name: dummy_input})\n",
    "print(f\"\\nInference Test erfolgreich!\")\n",
    "for i, out in enumerate(session.get_outputs()):\n",
    "    print(f\"  Output '{out.name}': shape={results[i].shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Schritt 6: Video-Test (optional)\n",
    "\n",
    "Teste das Modell auf einem ganzen Video."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Optional: Video-Test\n",
    "# Lade ein Test-Video hoch oder gib eine URL an\n",
    "\n",
    "TEST_VIDEO = \"test_match.mp4\"  # Pfad zum Test-Video\n",
    "\n",
    "if os.path.exists(TEST_VIDEO):\n",
    "    import cv2\n",
    "    \n",
    "    cap = cv2.VideoCapture(TEST_VIDEO)\n",
    "    fps = cap.get(cv2.CAP_PROP_FPS)\n",
    "    total_frames = int(cap.get(cv2.CAP_PROP_FRAME_COUNT))\n",
    "    \n",
    "    print(f\"Video: {TEST_VIDEO}\")\n",
    "    print(f\"FPS: {fps}, Frames: {total_frames}\")\n",
    "    \n",
    "    # Analyse: Jeden 5. Frame\n",
    "    ball_positions = []\n",
    "    frame_idx = 0\n",
    "    \n",
    "    while cap.isOpened():\n",
    "        ret, frame = cap.read()\n",
    "        if not ret:\n",
    "            break\n",
    "        \n",
    "        if frame_idx % 5 == 0:\n",
    "            image = Image.fromarray(cv2.cvtColor(frame, cv2.COLOR_BGR2RGB))\n",
    "            detections = model.predict(image, threshold=0.3)\n",
    "            \n",
    "            for j in range(len(detections)):\n",
    "                cls_name = detections.data.get('class_name', ['?'])[j] if 'class_name' in detections.data else '?'\n",
    "                if cls_name == 'ball':\n",
    "                    box = detections.xyxy[j]\n",
    "                    cx = (box[0] + box[2]) / 2\n",
    "                    cy = (box[1] + box[3]) / 2\n",
    "                    ball_positions.append({\n",
    "                        'frame': frame_idx,\n",
    "                        'time': frame_idx / fps,\n",
    "                        'x': float(cx / frame.shape[1]),\n",
    "                        'y': float(cy / frame.shape[0]),\n",
    "                        'conf': float(detections.confidence[j])\n",
    "                    })\n",
    "        \n",
    "        frame_idx += 1\n",
    "        if frame_idx % 100 == 0:\n",
    "            print(f\"  Frame {frame_idx}/{total_frames}...\")\n",
    "    \n",
    "    cap.release()\n",
    "    \n",
    "    print(f\"\\nBall erkannt in {len(ball_positions)} von {total_frames // 5} analysierten Frames\")\n",
    "    \n",
    "    # Ball-Positionen als JSON speichern\n",
    "    with open('ball_track.json', 'w') as f:\n",
    "        json.dump(ball_positions, f, indent=2)\n",
    "    print(\"Ball-Track gespeichert als ball_track.json\")\n",
    "else:\n",
    "    print(f\"Kein Test-Video gefunden ({TEST_VIDEO}). Ueberspringe Video-Test.\")\n",
    "    print(\"Lade ein Video hoch und setze TEST_VIDEO auf den Pfad.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Schritt 7: Modell herunterladen\n",
    "\n",
    "Lade `tt-detector.onnx` herunter und lege es in dein Projekt:\n",
    "\n",
    "```\n",
    "ttv-champions-web/\n",
    "  public/\n",
    "    models/\n",
    "      tt-detector.onnx    <-- HIER\n",
    "```\n",
    "\n",
    "Das Modell wird dann automatisch von `video-ai-detector.js` geladen."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Modell herunterladen (Google Colab)\n",
    "try:\n",
    "    from google.colab import files\n",
    "    files.download('tt-detector.onnx')\n",
    "    print(\"Download gestartet!\")\n",
    "except ImportError:\n",
    "    print(\"Nicht in Google Colab - lade die Datei manuell herunter:\")\n",
    "    print(f\"  {os.path.abspath('tt-detector.onnx')}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tipps fuer bessere Ergebnisse\n",
    "\n",
    "### Mehr Daten = besser\n",
    "- **300 Bilder**: Grundfunktion, viele Fehler\n",
    "- **1000 Bilder**: Gute Genauigkeit\n",
    "- **3000+ Bilder**: Sehr zuverlaessig\n",
    "\n",
    "### Augmentation in Roboflow\n",
    "- **Flip** (horizontal): Verdoppelt Datenmenge\n",
    "- **Brightness** (+/- 25%): Verschiedene Beleuchtung\n",
    "- **Blur** (0-2px): Simuliert Bewegungsunschaerfe\n",
    "- **Noise** (bis 5%): Robustheit gegen Rauschen\n",
    "\n",
    "### Schwierige Faelle\n",
    "- Ball hinter Netz (teilweise verdeckt)\n",
    "- Ball in der Luft (Bewegungsunschaerfe)\n",
    "- Verschiedene Ballfarben (weiss, orange)\n",
    "- Verschiedene Tischfarben (blau, gruen)\n",
    "- Verschiedene Kamerawinkel\n",
    "\n",
    "### Iteratives Training\n",
    "1. Trainiere mit 300 Bildern\n",
    "2. Teste auf neuen Videos\n",
    "3. Finde Fehler (False Positives/Negatives)\n",
    "4. Labele genau diese schwierigen Faelle\n",
    "5. Trainiere erneut mit erweitertem Dataset\n",
    "6. Wiederhole bis zufrieden"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "gpuType": "T4",
   "provenance": [],
   "name": "RF-DETR Tischtennis Training"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}